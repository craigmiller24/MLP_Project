{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline Models = Logistic Regression and Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary modules\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "merged_df = pd.read_csv('merged_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories learned by OneHotEncoder: [array(['JFK'], dtype=object), array(['LAX', 'SFO', 'SJU', 'PHX', 'TPA', 'RSW', 'FLL', 'PBI', 'BQN',\n",
      "       'MCO', 'ATL', 'MIA', 'STT', 'MSY', 'LAS', 'BOS', 'SLC', 'SRQ',\n",
      "       'MSP', 'BUR', 'DEN', 'HOU', 'LGB', 'SYR', 'JAX', 'SEA', 'AUS',\n",
      "       'PWM', 'RIC', 'RDU', 'OAK', 'IAD', 'DTW', 'ORD', 'BTV', 'BUF',\n",
      "       'ROC', 'SAN', 'DCA', 'CLT', 'PIT', 'CVG', 'PHL', 'BWI', 'EGE',\n",
      "       'MCI', 'BGR', 'CLE', 'SJC', 'SMF', 'ALB', 'BDL', 'IAH', 'PDX',\n",
      "       'IND', 'STL', 'MKE', 'BNA', 'ORF', 'PSE', 'DFW', 'CMH', 'MEM',\n",
      "       'ACK', 'SNA', 'SAT', 'LWB', 'MVY', 'HNL', 'PSP', 'CHS', 'SDF',\n",
      "       'ABQ', 'BHM', 'JAC', 'SAV', 'HYA', 'RNO', 'DAB', 'TUS', 'ORH'],\n",
      "      dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Define target variables and feature variables\n",
    "X = merged_df.drop(columns=['DEP_DATE_TIME', 'ACC_DEP_TIME', 'DEP_DELAY_NEW', 'DEP_DELAY_GROUP'])\n",
    "y = merged_df['DEP_DELAY_GROUP']\n",
    "\n",
    "# Replace -2 and -1 with 0 in the target labels\n",
    "y = y.replace({-2: 0, -1: 0})\n",
    "\n",
    "# Define numerical and categorical columns \n",
    "categorical_cols = ['ORIGIN', 'DEST']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ensure encoder learns all categories, even those missing in training\n",
    "all_categories = {col: X[col].unique() for col in categorical_cols}\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(categories=[all_categories[col] for col in categorical_cols], drop='first', handle_unknown='ignore'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Preprocess the data\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.FloatTensor(X_train_processed.toarray())  # Use toarray() if sparse matrix\n",
    "Y_train = torch.LongTensor(Y_train.values)\n",
    "X_test = torch.FloatTensor(X_test_processed.toarray())\n",
    "Y_test = torch.LongTensor(Y_test.values)\n",
    "\n",
    "# Normalize data\n",
    "scaler = StandardScaler()\n",
    "X_train = torch.tensor(scaler.fit_transform(X_train), dtype=torch.float32)\n",
    "X_test = torch.tensor(scaler.transform(X_test), dtype=torch.float32)\n",
    "\n",
    "# Debugging: Print categories learned by OneHotEncoder\n",
    "print(\"Categories learned by OneHotEncoder:\", preprocessor.named_transformers_['cat'].categories_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 2.6242\n",
      "Epoch [20/100], Loss: 2.5513\n",
      "Epoch [30/100], Loss: 2.4798\n",
      "Epoch [40/100], Loss: 2.4096\n",
      "Epoch [50/100], Loss: 2.3410\n",
      "Epoch [60/100], Loss: 2.2739\n",
      "Epoch [70/100], Loss: 2.2085\n",
      "Epoch [80/100], Loss: 2.1446\n",
      "Epoch [90/100], Loss: 2.0825\n",
      "Epoch [100/100], Loss: 2.0221\n",
      "Accuracy: 0.6293\n"
     ]
    }
   ],
   "source": [
    "# Implement multinomial logistic regression\n",
    "\n",
    "# Define multinomial logistic regression model\n",
    "class MultinomialLogisticRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MultinomialLogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)  # Softmax is included in CrossEntropyLoss\n",
    "\n",
    "# Model, loss, optimizer\n",
    "input_dim = X_train.shape[1]  # Number of features after preprocessing\n",
    "output_dim = len(torch.unique(Y_train))\n",
    "model = MultinomialLogisticRegression(input_dim, output_dim)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # Includes softmax\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, Y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate accuracy\n",
    "model.eval()  # Set model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    y_pred = torch.argmax(model(X_test), dim=1)\n",
    "    accuracy = (y_pred == Y_test).float().mean()\n",
    "    print(f'Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.7488\n",
      "Epoch [20/100], Loss: 0.6241\n",
      "Epoch [30/100], Loss: 0.5269\n",
      "Epoch [40/100], Loss: 0.4737\n",
      "Epoch [50/100], Loss: 0.4379\n",
      "Epoch [60/100], Loss: 0.4060\n",
      "Epoch [70/100], Loss: 0.3753\n",
      "Epoch [80/100], Loss: 0.3473\n",
      "Epoch [90/100], Loss: 0.3236\n",
      "Epoch [100/100], Loss: 0.3050\n",
      "Accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "# Define a simple neural network model\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)  # Fully connected layer\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, num_classes)  # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x  # No softmax since CrossEntropyLoss expects raw logits\n",
    "\n",
    "# Initialize model\n",
    "input_size = X_train.shape[1]\n",
    "y = merged_df['DEP_DELAY_GROUP'].values\n",
    "num_classes = len(np.unique(y)) # Number of unique labels\n",
    "model = SimpleNN(input_size, num_classes)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, Y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "    y_pred_classes = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(Y_test.numpy(), y_pred_classes.numpy())\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "\n",
    "# dont know if we need to do this but here's how to visualise the tree\n",
    "# plt.figure(figsize=(12,8))\n",
    "# tree.plot_tree(clf, filled=True, feature_names = data.feature_names, class_names = data.target_names)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlpc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
